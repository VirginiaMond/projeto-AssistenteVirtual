from memory import carregar_memoria, salvar_memoria, criar_usuario
from config.settings import llm
from agent import criar_agente
from history import get_history_for_langchain, llm_com_memoria
from context import construir_contexto
from agent_run import executar_agente
from regex import atualizar_dados_usuario
from prompt import instrucoes_mochi
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from google.api_core.exceptions import ResourceExhausted, InvalidArgument
from utils.formatters import deve_buscar_passagem
from datetime import datetime

def iniciar_chat_terminal():
    #carrega os dados de usu√°rio salvo 
    memoria = carregar_memoria()
    if memoria is None:
        memoria = {}
    
    print("========== Assistente Virtual Mochi ^^ ==========")
    username = input("Por gentileza, me diga seu nome/id que queira utilizar: ")
    usuario = criar_usuario(username, memoria)
    #se n estiver preenchido, define
    if not hasattr(usuario, 'nome') or usuario.nome is None:
        usuario.nome = username

    agente_passagens = criar_agente(llm, usuario) #cria o agente que ser√° usado para buscar passagens
    awaiting_search_confirmation = False #flag para saber se o usu√°rio est√° prestes a confirmar a busca

    while True:
        entrada = input("\nVoc√™: ")
        salvar_memoria(memoria)
        if entrada.lower() in ["sair", "exit"]:
            print("Mochi: Tudo bem! Se precisar de mim depois, √© s√≥ voltar ‚Äî estarei por aqui. Boa viagem e at√© logo! ‚úàÔ∏èüåü")
            salvar_memoria(memoria)
            break
        #atualiza os dados extraidos da frase
        atualizar_dados_usuario(entrada, usuario)
        salvar_memoria(memoria)
        
        #logica para confirmar busca
        if awaiting_search_confirmation:
            if "sim" in entrada.lower():
                print("MOCHI: √ìtimo! Realizando a busca de passagens agora...")
                dados_passagens = executar_agente("buscar passagens", usuario, agente_passagens)
                if dados_passagens:
                    #Gera uma chave √∫nica baseada no timestamp
                    chave_passagem = f"busca_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
                    # Adiciona ao dicion√°rio de passagens
                    if not hasattr(usuario, 'passagens') or not isinstance(usuario.passagens, dict):
                        usuario.passagens = {}
    
                    usuario.passagens[chave_passagem] = dados_passagens
                    #if not hasattr(usuario, 'passagens'):  
                        #usuario.passagens = {}  
                        # Adicione os dados
                    #usuario.passagens.append(dados_passagens)  
                    print("MOCHI: Aqui est√£o os dados das passagens encontradas:")
                    print(dados_passagens)
                    salvar_memoria(memoria)
                else:
                    print("MOCHI: N√£o foi poss√≠vel realizar a busca no momento, pode tentar novamente mais tarde.")
                awaiting_search_confirmation = False
                continue
            elif "n√£o" in entrada.lower():
                print("MOCHI: Entendido. Posso te ajudar com outra coisa?")
                awaiting_search_confirmation = False
                salvar_memoria(memoria)
                continue
        #monta o contexto da conversa
        contexto = construir_contexto(usuario, entrada)
        human_message_content = contexto.strip()
        
        if not human_message_content: #se estiver vazio
            human_message_content = "Informa√ß√µes de contexto e entrada do usu√°rio foram fornecidas, mas sem conte√∫do espec√≠fico."
        #carrega instru√ß√µes/prompt inicial do sistema 
        #system_message_content = instrucoes_mochi.strip()
        # Substituir instru√ß√µes com nome do usu√°rio
        system_message_content = instrucoes_mochi.strip().replace("{nome}", usuario.nome or username)

        if not system_message_content:
            system_message_content = "Voc√™ √© um assistente de viagens de IA."

        #print("DEBUG - CONTEXTO:", contexto)
        #cria a sequencia de mensagens para o LLM
        mensagens = [
            SystemMessage(content=system_message_content)
        ]
        # Adiciona hist√≥rico anterior (limitando a 10 √∫ltimas intera√ß√µes, por seguran√ßa)
        #for msg in usuario.chat_history[-5:]:
            #mensagens.append(msg)
        
        if human_message_content:
            mensagens.append(HumanMessage(content=human_message_content))
        
        # Filtro para remover mensagens vazias (protegendo o Gemini)
        mensagens = [msg for msg in mensagens if msg.content and msg.content.strip()]

        try:
            #envia as mensagens para o modelo com memoria de sess√£o
            resposta = llm_com_memoria.invoke( 
                {"messages": mensagens},
                config={"configurable": {"session_id": username}}
            )
            #trata o retorno
            texto_resposta = resposta.content if isinstance(resposta, AIMessage) else str(resposta)
            if not texto_resposta.strip(): # Fallback se a resposta do LLM for vazia
                texto_resposta = "Desculpe, n√£o consegui gerar uma resposta significativa. Tente novamente."
            print("MOCHI:", texto_resposta)
        
        #tratamentos de erros
        except (ResourceExhausted, InvalidArgument) as e:
            print(f"MOCHI: Ocorreu um erro ao comunicar com a IA (Quota Excedida ou Argumento Inv√°lido). Erro: {e}")
            texto_resposta = "Erro de servi√ßo da IA. Por favor, tente novamente mais tarde."
            print("MOCHI:", texto_resposta)
        except Exception as e:
            print(f"MOCHI: Ocorreu um erro inesperado: {e}")
            texto_resposta = "Erro interno do chatbot. Tente novamente."
            print("MOCHI:", texto_resposta)
        
        #atualiza o historico
        if usuario.chat_history is None:
            usuario.chat_history = []
        #adiciona pergunta e resposta ao historico
        entrada = entrada.strip() if entrada.strip() else "(Pergunta do usu√°rio vazia)"
        texto_resposta = texto_resposta.strip() if texto_resposta.strip() else "(Resposta do BOT vazia)"
        # Evita duplica√ß√£o de mensagens
        if not usuario.chat_history or usuario.chat_history[-1].content != entrada:
            usuario.chat_history.append(HumanMessage(content=entrada))
        if not usuario.chat_history or usuario.chat_history[-1].content != texto_resposta:
            usuario.chat_history.append(AIMessage(content=texto_resposta))
        
        #recupera dados mais recentes do usuario
        prefs = usuario.preferencias
        dadosnovos = usuario.dadosviagem
        finalidade = usuario.finalidade
        origem = dadosnovos.get("origem")
        destino = dadosnovos.get("destino")
        dia = dadosnovos.get("dia")
        
        dados_completos = origem and destino and dia

        # Caso o usu√°rio j√° tenha dito para buscar
        if dados_completos and deve_buscar_passagem(entrada) and not awaiting_search_confirmation:
            print("MOCHI: Perfeito! Buscando passagens agora...")
            dados_passagens = executar_agente(entrada, usuario, agente_passagens)
            if dados_passagens:
                salvar_memoria(memoria)
            else:
                print("MOCHI: N√£o consegui encontrar passagens agora.")
            continue
        # Caso os dados estejam completos, mas o usu√°rio ainda n√£o pediu a busca
        elif dados_completos and not awaiting_search_confirmation:
            print("MOCHI: Deseja que eu realize a busca agora? (sim/n√£o)")
            awaiting_search_confirmation = True
            salvar_memoria(memoria)
            continue
        
        # Se o usu√°rio estiver respondendo "sim" ap√≥s a pergunta
        elif entrada.lower() in ["sim", "pode buscar", "sim, por favor"] and awaiting_search_confirmation:
            print("MOCHI: Certo! Buscando as passagens agora...")
            dados_passagens = executar_agente(entrada, usuario, agente_passagens)
            if dados_passagens:
                salvar_memoria(memoria)
            else:
                print("MOCHI: N√£o consegui encontrar passagens agora.")
            awaiting_search_confirmation = False
            salvar_memoria(memoria)
            continue

        #confirma ou aciona busca autom√°tica
        # (Opcional) Detecta quando o usu√°rio quer informar a finalidade
        elif "trabalho" in entrada.lower() or "lazer" in entrada.lower():
            finalidade = "trabalho" if "trabalho" in entrada.lower() else "lazer"
            print(f"MOCHI: Entendi que sua viagem √© a passeio de {finalidade}. üòâ")
            salvar_memoria(memoria)
            continue   
        
        salvar_memoria(memoria)


if __name__ == "__main__":
    iniciar_chat_terminal()
